---
hide:
    - navigation
    - toc
---
# Data is Beautiful

## Part I

??? quote "<strong>Spring</strong>, by Jimmy Santiago Baca"
    <p class="quote-indent">With one might tug and push, conservancy engineers</p>

    in North New Mexico

    <p class="quote-indent">open water gates--snow melt,

    brimming northern lakes, and streams

    <p class="quote-indent">gush, lunge, and hurl down Río Abajo to community fields,

    <p class="quote-indent">fill the dry ditches and canals, clashing</p>
        
    like great banging orchestra cymbals
    
    against dirt. Plants, bushes, weeds
    
    <p class="quote-indent">uncurl, furl out along my ditch,</p>
    
    <p class="quote-indent">ants float on islands of leaves,</p>
    
    <p class="quote-indent">past pyramids of beer cans,</p>
    
    <p class="quote-indent">tadpoles fuse to the water</p>
    
    <p class="quote-indent">in swirls of brown mist,</p>
    
    <p class="quote-indent">catfish fin beneath driftwood</p>
    
    <p class="quote-indent">and stew the water dark brown.</p>
    
    All things pull and strain. The ditch swells
    
    into a great marketplace, where death and life
    
    are exchanged.
    
    A pair of light blue-gray doves skim water surface,
    
    geese veer down, royal couriers
    
    flap-landing in gusty sprinkles, then
    
    serenely floating like white flags of peace,
    
    drifting in pairs, through glare and shadows,
    
    <p class="quote-indent">as crawdads, spiders, snakes and frogs</p>
    
    <p class="quote-indent">peer from mud and weed corners.</p>


    From each unfolding lilac leaf
    
    a blue-green arctic haze glimmers,
    
    from feathers dark winter melts,
    
    from eyes glide out cold deeps,
    
    everything bears a new light.
    
    The crane is breaking ice with its call,
    
    long-legged spider skitters
    
    to birth-thawing rhythms of the shore,
    
    as spring finally arrives,
    
    glistening the dead-slag of winter
    
    in all creatures,
    
    as they emit that special light
    
    they do.

??? note "Exploring the Value of Data: A Journey Through the Wilderness"
    ## Exploring the Value of Data: A Journey Through the Wilderness

    !!! quote "The universe is wider than our views of it."
        <strong>Henry David Thoreau</strong>

    <span class="lg-letter">D</span>ata is a powerful tool for conveying ideas, just as words can tell a story or art can depict the world. Splunk is software that helps people understand and make sense of their data.

    This data story begins at the Dripping Springs trailhead in the Organ Mountains in Southern New Mexico, which recently became a protected national monument. Before setting out on my hike, I used my phone to check the weather forecast and made sure to pack my rain jacket. As I started my hike, I wore my Apple Watch, which tracked my GPS location, blood oxygen levels, heart rate, and other telemetry. My phone and watch provided me with real-time information about the weather and my location as I hiked. When it began to rain, I consulted my phone's weather radar app and decided to continue based on the information it provided and my own observations.

    The desert smells wonderful when it rains. The hot ground is cooled as rain drops evaporate. The hike was enjoyable, and my trail app showed me that I had traveled a total distance of 4.95 miles in 2.5 hours, climbed 62 flights of stairs, and burned 1440 calories. It also recorded my heart rate and oxygen levels at 5-minute intervals throughout the hike. This is just one example of the vast amount of data that can be generated and consumed in a single activity. 

    All of the devices I had with me, including my phone, smartwatch, headphones, and even my AirPods, were capable of generating and streaming data. Two of these devices, my phone and watch, were also connected to cellular networks and had GPS capabilities. These devices provided me with valuable information when I needed it and also captured my personal biometric data, giving me insights into how my body responded to the hike. Let's look at a few more examples of how data and insights can be useful. Some examples of data that were valuable to me include:

    - Weather data: This was useful to me before and during my hike, but would not be valuable to me a week after the hike.
    - Location information: This was useful to me in real-time to show my exact location on a map and also valuable to me after the hike so I could look back at where I had previously hiked.
    - Health information: This is valuable to me when aggregated with other data, as it allows me to see trends over time and track my fitness metrics.
    - Geolocation information embedded in photos: This will be valuable to me when I want to filter my photos by location.

    It's important to note that not all data is valuable after the fact. In my case, an incredible amount of data was generated, collected, and analyzed during my hike, and this data was valuable to different people and at different times. For example, the data collected by my devices was useful to me when I wanted to track my fitness or explore my hiking routes, but it might not be as valuable to someone else.

    It's also worth considering that even when our devices are turned off, data is still being generated. The absence of data can be a data point in itself. For example, a cellular provider might be interested in knowing when 1% or more of all connected cell phones disconnect and stop sending data.

    At the center of all this is me, the consumer of insights and the generator of data through my use of devices. As I use these devices for different activities and tasks, I create patterns and routines that are unique to me, and the way I navigate digital spaces becomes a data point in itself. Ultimately, I believe that data is evidence of our relationship with machines.

    !!! quote "Maybe stories are just data with a soul."
        <strong>Brené Brown Research Professor and Author</strong>

??? note "Bringing Data to Life: A Practical Approach to Building an Analytics Center of Excellence"
    ## Bringing Data to Life: A Practical Approach to Building an Analytics Center of Excellence

    Data is a valuable resource, just like water is in arid regions like New Mexico. In the same way that farmers must carefully manage their water rights and usage through contracts and agreements, organizations must also carefully manage their data to get the most value out of it. One way to do this is by building an Analytics Center of Excellence (ACE), which can help an organization make the most of its data by providing a central hub for data analytics and visualization.

    <figure markdown>
        ![ACE](/assets/data-is-beautiful/ace.png){ width="800" }
    </figure>

    The poem "Spring" by Jimmy Santiago Baca describes the arrival of spring in North New Mexico, as water flows into the acequia and brings life to the community fields. The acequia  (ə-ˈsā-kē-ə), or network of canals, acts as a conduit for water, just as networks of data conduits can help organizations distribute insights and information to users.

    In the same way that the acequia association helps to manage water rights and ensure the smooth bureaucratic flow of water to the fields, an ACE can help an organization manage data rights and ensure the smooth flow of data insights to users. The ACE can serve as a resource for answering questions and addressing issues related to data analytics.

    ??? tip "Aspirations of an ACE"
        ### Aspirations of an ACE

        The Seven Goals (aka, [VAULTIS](https://www.defense.gov/News/Releases/Release/Article/2376629/dod-issues-new-data-strategy/){ target="_blank" }) to become a data-centric organization, as outlined by the Department of Defense, are:

        1. Make Data Visible: Enabling consumers of data to easily locate and search for the data they need.
        1. Make Data Accessible: Ensuring consumers of data can retrieve and access the data they need.
        1. Make Data Understandable: Ensuring that the context, content and applicability of the data is clear and comprehensive
        1. Make Data Linked: Exploiting innate relationships between data elements to allow easy connections and understanding of relationships
        1. Make Data Trustworthy: Implementing robust data quality controls to ensure data is accurate, complete, and up-to-date
        1. Make Data Interoperable: Implementing standards for data representation and comprehension, to ensure easy sharing and use across different systems and platforms
        1. Make Data Secure: Protecting consumer data from unauthorized use or manipulation by implementing security controls and measures such as encryption, access controls, and monitoring systems.

        Achieving these goals would help an organization to become data-centric, which would allow them to make better data-driven decisions, identify opportunities for innovation, and improve overall efficiency. With the ability to monitor real-time actions and gather evidence across channels, it is important to ensure that the service meets the needs and expectations of customers and users. By achieving these seven goals, organizations will ensure that data is discoverable, accessible, usable, linked, and trustworthy.

        Here are some potential impacts that an ACE may have in your environment.

        <figure markdown>
            ![Impacts of an ACE](/assets/data-is-beautiful/impacts.png){ width="800" }
        </figure>

??? note "Understanding the Hierarchy of Data Value"
    ## Understanding the Hierarchy of Data Value

    When it comes to data, not all data are created equal. In fact, there are different tiers of value when it comes to data, each serving a specific purpose.

    - Tier 1 data is considered the most valuable, as it is used frequently and requires quick access. This type of data is typically stored on high-speed storage systems for efficient searching.
    - Tier 2 data is accessed less frequently, and therefore is stored on different storage systems. It may not require the same level of speed as Tier 1 data, but it is still considered important to the organization.
    - Tier 3 data is considered the least valuable, but it is still important for compliance purposes such as eDiscovery. This type of data is stored long-term, but is not accessed as frequently as the other tiers.

    The value of data can be determined by a number of factors, including search frequency, performance, capabilities, classification, compliance, governance, and location. For example, firewall logs may be important for cybersecurity and IT operations, but not necessarily for the desktop support team.

    By understanding the hierarchy of data value, organizations can better align their IT infrastructure and contextualize their data for the appropriate audience. Using the IT Service Blueprint method, organizations can map out the technology used to provide IT services to specific populations of users. This helps to ensure that the right data is being collected, stored, and accessed in the most efficient and effective way possible. 

??? note "The Role of Data Analytics in Transforming Decision Making Processes"
    ## The Role of Data Analytics in Transforming Decision Making Processes

    Ultimately this comes down to: <em>what should I do right now vs. what can I delay or hold off on until the priorities are taken care of?</em>

    When you use data to navigate in a new city or check the weather in your current location, you have applied value to that insight. This is proven by you taking the action of bringing out your phone or glancing at your smart watch. When your gaze lands on the weather app icons, you have placed some trust into the weather insights and can make a decision based on current and trustworthy information. 

    Out of curiosity, would you wait up to 30 seconds for weather data for the trip you are taking next week? Would you wait up to a minute… or five? What if you had to wait an entire day for the insights? There is a balance between time, availability, usefulness, and accessibility when it comes to data-driven decision making. If I have to fumble through a series of clicks on my phone to get the weather forecast, I might just revert to the news on TV or a newspaper. If neither of those are available, I will just take my umbrella anyway!

    There’s a common thread across every level of an organization - that is, we all want to make the best choice for the business, the customer, and the team. In some cases (Public Sector), there is a life or death scenario that must be factored into every decision when it comes to IT. If someone’s life depends on it, would you install a secondary (backup) internet connection? Did you know that there is very little (if any) regulation on how counties are to prepare the IT environment in the interest of human life. In other words, the jail’s internet connection goes down and risk goes up. What if there were a backup, secondary ISP (internet service provider) providing access so that the doors can be opened - allowing medical response personnel access to a detainee who is having a seizure.

    If we are to put this much effort into our technology to prevent the loss of life, we surely need to be able to trust the data. If an ambulance does not have the correct information on the patient and how to get to them, they could increase the risk of someone losing their life. The ambulance needs to be able to not only navigate efficiently to the scene, but also navigate to the hospital while providing life-saving care. 

    We don’t have time to get into it, but all of this makes me think of entropy, likelihood, and possibilities. The possibilities are endless and equally exciting. The power of data analytics has transformed our day-to-day lives and will continue to do so. We are in the midst of something big. Web3, blockchain, decentralized systems, IoT, and AI are all emerging technologies that will change our world.

    Endless, huh?…. So where does one begin? What is the best course of action?

??? note "Storytelling With Data"
    ## Storytelling With Data

    !!! quote "Stories have been used to dispossess and malign, but stories can also be used to empower and to humanize. Stories can break the dignity of a people, but stories can also repair that broken dignity."
        <strong>Chimamanda Ngozi Adichie, The Danger of a Single Story, TED Talk</strong>

    There are many wonderful people out there creating content and enablement material (practical wisdom) about storytelling with data. Brent Dykes wrote an excellent book called, Effective Data Storytelling and Cole Nussbaumer Knaflic has published multiple books; Storytelling With Data and recently, Storytelling With You. 

    What I will say here in this article is this: 1) get and read those books and 2) start by telling your data story. What do you measure, monitor, and track? For me, I religiously track my spend on fuel in a smartphone app that tracks gas mileage. I can look at this app’s dashboard for my vehicle and tell you exactly (I have missed a few fill ups) how much I spent on fuel in the last 182,000 miles. I can tell you how much I have spent (approximately) on fuel in the last 10 years. This app tells me a lot and has many more capabilities to track maintenance like oil changes and tires. Why do I use it? I have been tracking different things since I figured out how to use spreadsheets…. It’s a thing I do! But… through that experience, I reckon (John Dutton voice) it is helpful to share your data story with other people. This will help us all practice and find common language. 

    Jordan Morrow writes in his book, Be Data Literate, about the lack of a common language with regard to data. He also talks about the four levels of analytics; descriptive, diagnostic, predictive, and prescriptive and the three Cs - which I’ll cover later in Part III. When we frame things using these four levels, we can identify our common language. 

    The gas mileage app is providing me with descriptive analytics about spend, fuel consumption, vehicle wear and tear, and maintenance. If the mile per gallon suddenly drops, we can ask why and look for an answer. Was it because of headwinds, towing, or because I was late and driving fast. (Of course I would never speed!)

    Based on these insights, I can predict how much I will spend on fuel next month or next year.

    As you read in the beginning of this writing, I attempted to capture your interest and attention with my data story. As you find new ways to share how you consume and generate data, you also begin developing new ways of hearing data stories. The US Census made a lot more sense to me when I learned more about how data is collected and used. This becomes incredibly important when it comes to demographics or social profiles. As these skills develop, one might see Facebook, TikTok, and other social media apps a little differently simply based on the fact that your data is being used for their financial gain. But I digress! 

    Stories are powerful as you read in this section’s opening quote. Chimamanda accurately points out that stories are so powerful that they can replace governments, marginalize groups or individuals, or create division where there might not be (or not as much). 

    With so many stories and attempts to capture your attention, we - as people - tend to become overwhelmed. There is a lot of noise, many signals, and sometimes too many options. How do we decide?

    !!! quote "A wealth of information creates a poverty of attention."
        <strong>Herbert A. Simon, Economist and Political Scientist</strong>

    As individuals, we often make tough decisions based on our values and ethics. These core beliefs guide us and help us navigate difficult situations. Similarly, in business, we rely on frameworks, standards, protocols, and processes to guide our decision-making. We may measure our progress against established baselines to ensure that we are on track.

    When it comes to discussing data and insights, it is important to provide context and background information to help listeners understand and calibrate their thinking. For example, if we are discussing cybersecurity capabilities, we might use the MITRE ATT&CK framework to describe our progress in preventing lateral movement. By providing a clear and concise description of the insights being discussed, and how they align with a well-known framework or baseline, we can enable others to make informed decisions.

    In today's world, it is crucial that we learn to identify and call out misinformation. Misinformation and propaganda have always been present, but with the proliferation of digital media, it is more important than ever to be able to distinguish between reliable and unreliable sources. By establishing a common language and understanding, we can have more meaningful and effective communication and discussions.

    !!! quote "It is a capital mistake to theorize before one has data."
        <strong>Sherlock Holmes A Study in Scarlet, Arthur Conan Doyle</strong>

    ??? tip "Storytelling with Data: The Importance of Considering the User"
        ### Storytelling with Data: The Importance of Considering the User

        The success of any data storytelling lies in its ability to engage and reach the emotion of the audience. It is crucial to consider who your audience is and tailor your presentation accordingly. While a technical audience with a high level of data literacy may be able to comprehend more complex language and visualizations, a non-technical audience may require simpler explanations, basic data visualizations, or a walk-through of what’s being presented. Using metaphors and analogies are very helpful tools when customizing your presentation or content.

        It is also essential to consider their goals, interests, and motivations. What do they hope to learn from the data? How can the insights from the data be applied to their needs? By aligning your data storytelling with the audience's needs and interests, you can create a relevant and engaging story or presentation that effectively communicates the value of the data.

        Finally, when considering the context of the data, user stories can also be used to identify key insights and actionable steps that can be taken based on those insights. This helps to make the data more valuable and applicable to your audience, and helps them understand the implications of the data.

??? note "Data at the Heart of Modern Life"
    ## Data at the Heart of Modern Life

    In this section, we will explore the 5 Vs, the growth of IoT and sensing devices, the impact of mobile and cloud computing on data generations, and the importance of data in a pandemic.

    As our world becomes increasingly digitized, we are generating and collecting vast amounts of data from a variety of sources. From the sensing devices placed throughout our physical environment to the data we create through our daily interactions and activities, the amount of data we produce is vast and ever-growing.

    But data is more than just a collection of numbers and information. It is a precious resource, one that will last long after the systems and technologies that generate it have come and gone. As Tim Berners-Lee said,

    !!! quote "Data is a precious thing and will last longer than the systems themselves."

    In the future, we will see data play an even greater role in our lives as technologies like blockchain allow us to exchange value peer-to-peer using digital infrastructure. Autonomous vehicles, energy grids, entertainment, and transportation will all be transformed by the power of data. Data is a valuable resource that will shape our world for generations to come.

    As more people and more things become connected, more data is generated, consumed, analyzed, stored, destroyed, and valued. 

    Using blockchain technology, we can exchange value for the first time - peer-to-peer - using digital infrastructure. Fun fact: the only other peer-to-peer infrastructure we have to exchange value is cash. 

    The future motivates me, personally. I love technology and love thinking about all the ways that we humans will interact with and experience technology. AR, VR, xVR, whatever the reality, it sounds cool and I look forward to it!

    ??? tip "The 5 Vs of Data Analytics"
        ### The 5 Vs of Data Analytics

        Data plays a central role in modern life, and organizations of all types and sizes are facing challenges in managing the volume, variety, veracity, velocity, and value of the data they generate and collect. From states to universities, counties to tribes and pueblos, school districts to utilities, academic medical centers to businesses, the challenges of data management are widespread and complex. In this section, we will delve into each of the 5Vs and explore the key considerations for an effective data strategy.

        ??? info "Volume"
            #### Volume

            As organizations continue to digitize, the volume of data being generated on a daily basis has become overwhelming. In fact, according to recent estimates, the average digital organization creates terabytes of data each day. Here’s a list of some important questions to consider, as the volume of data can have a significant impact.
            
            - How much data does your digital organization create every day?
            - How much of that data that is created by the organization needs to be collected?
            - How much of the data is clean and is usable?
            - How much of that data that is collected needs to be analyzed or processed?
            - How much of that data that is collected needs to be retained?
            - How will the volume of data impact the organization’s governance program?
            - How much of the digital organization’s data is not being collected?
            - Volume can be derived from # of users, # of endpoints, and other factors.
        
        ??? info "Variety"
            #### Variety

            There is a growing movement within the cybersecurity industry to establish a common standard for sharing threat intelligence and communicating threat tactics and techniques. For example, Splunk recently announced a partnership with Amazon Web Services (AWS) to create the Splunk Security Lake, which aims to provide a centralized platform for storing, analyzing, and sharing security data. However, until there is a widely-accepted industry-wide standard for data sharing, organizations will continue to deal with a variety of data sources.

            Each firewall vendor has a different log format, and endpoint telemetry may contain more information than what is reported by the firewall. While these data sources can complement each other, the differences in format can make it difficult for organizations to effectively analyze and utilize the data. Splunk provides tools that can help normalize this variety of data using a Common Information Model (CIM). By using CIM, organizations can more easily integrate and analyze data from multiple sources, enabling them to make more informed security decisions.
            
            The following five items are key components of a successful data analytics program:

            `Integration`
            : This refers to the process of combining data from multiple sources, such as databases, systems, and applications, in order to gain a more comprehensive understanding of the data.

            `Quality`
            : Ensuring the quality of data is critical for accurate analysis and decision-making. This includes verifying the accuracy, completeness, and consistency of the data.

            `Governance`
            : Data governance is the set of policies, procedures, and standards that govern the use, management, and protection of data within an organization. It helps to ensure that data is used ethically and responsibly.

            `Security`
            : Protecting data from unauthorized access and ensuring the confidentiality, integrity, and availability of data is essential for any organization.
            
            `Analysis`
            : This refers to the process of examining, transforming, and modeling data in order to discover useful insights and inform decision-making. It can involve a variety of techniques, such as statistical analysis, machine learning, and data visualization.

        ??? info "Veracity"
            #### Veracity

            Ensuring the veracity of data is essential for a successful data analytics platform. This includes considering factors such as accuracy, completeness, timeliness, consistency, and integrity, as these all contribute to the overall quality of the data. Ensuring that the data is of high quality is critical for accurate analysis and informed decision-making. There are multiple points of importance when it comes to the veracity of data:
   
            `Accuracy`
            : Veracity refers to the truthfulness and accuracy of data. Data that is not accurate or reliable can lead to incorrect insights and decisions, which can have serious consequences for an organization.
            
            `Completeness`
            : Veracity also refers to the completeness of data. Data that is incomplete or missing key elements can impact the accuracy of analytics and insights, as well as the usefulness of the data for decision-making.
            
            `Timeliness`
            : Veracity also refers to the timeliness of data. Data that is not up-to-date or current can be less useful for decision-making, as it may not reflect the current state of the organization or industry.
            
            `Consistency`
            : Veracity also refers to the consistency of data. Data that is not consistent or does not follow established standards and conventions can be difficult to use and integrate, and may lead to incorrect insights and decisions.
            
            `Integrity`
            : Veracity also refers to the integrity of data. Data that has been compromised or altered in any way can impact the accuracy and reliability of analytics and insights, as well as the trustworthiness of the data for decision-making. Ensuring the veracity of data is critical for the success of any data analytics and decision-making efforts.

        ??? info "Velocity"
            #### Velocity

            Data velocity is a measure of how fast data is being generated and processed. It is calculated using two factors: time and amount. Speed, frequency, volume, and variety are all components of data velocity that can impact how quickly data is generated and processed.

            Imagine trying to measure the flow of electricity in a circuit. Just like electricity, data can flow at different speeds and in different quantities. To accurately measure the flow of electricity, you would need to consider factors such as the amount of current (similar to volume in data), the frequency of the current (similar to frequency in data), and the type of load on the circuit (similar to variety in data). Similarly, to measure data velocity, you need to consider the speed at which data is generated, the frequency of data generation, the volume of data being generated, and the variety of data being generated.

            Understanding data velocity is important because it can help organizations make informed decisions about how to process and store data. For example, if an organization is dealing with high velocity data, it may need to invest in more powerful and efficient processing and storage systems in order to keep up with the volume and speed of data being generated. On the other hand, if an organization is dealing with low velocity data, it may be able to use less expensive and less powerful systems to process and store the data. By understanding data velocity, organizations can ensure that they have the right systems and infrastructure in place to support their data analytics efforts.
            
            Breaking down speed, frequency, volume, and variety:

            `Speed`
            : The velocity of data refers to how quickly data is generated and processed. With the increasing amount of data being generated, it is important for organizations to have the ability to process and analyze data in real-time or near real-time to keep up with the pace of change.
            
            `Frequency`
            : The velocity of data also refers to the frequency at which data is generated and updated. Data that is generated and updated frequently may be more useful for decision-making, as it can provide a more current and accurate picture of the organization or industry.
            
            `Volume`
            : The velocity of data is also impacted by the volume of data being generated. Organizations that generate a high volume of data may need to invest in more advanced technologies and processes to handle the volume and velocity of data effectively.
            
            `Variety`
            : The velocity of data can also be impacted by the variety of data being generated. Data that comes from a variety of sources and formats may be more difficult to process and analyze quickly, which can impact the velocity of data.

        ??? info "Value"
            #### Value

            - What is the value of a seashell? 
            - What is the value of a goat or a chicken?
            - What is the value of 1 BTC?
            - How about a Peso?
            - The value of a piece of art is determined by a number of factors.
            - The value of music, a concert ticket, or the autographed poster are all complex equations.
            - What is the value of an hour of your time?

            The value of something is determined by how much it is worth to an individual or group. This value can be subjective and can vary depending on a variety of factors. For example, the value of a seashell may be different for one person compared to another, depending on the individual's personal preferences and circumstances. Similarly, the value of data and data analytics can vary depending on the context and purpose for which they are being used.

            Data itself can have value, as it can be used to inform decisions and drive business outcomes. Data analytics is the process of examining, transforming, and modeling data in order to discover useful insights and inform decision-making. The value of data analytics lies in its ability to provide valuable insights and help organizations make informed decisions.

            Insights are the information or understanding gained from data analytics. They can provide valuable perspective and help organizations make better decisions. The value of insights depends on their relevance, timeliness, and usefulness to the organization. By understanding the value of data, data analytics, and insights, organizations can maximize their value and achieve better outcomes.

    ??? tip "The Growth of IoT and Sensing Devices"
        ### The Growth of IoT and Sensing Devices

        The internet of things (IoT) refers to the growing network of interconnected devices, sensors, and other electronic devices that are able to collect, transmit, and exchange data. These devices are becoming increasingly prevalent in many areas of our lives, including homes, cities, transportation systems, and businesses. The rise of IoT and sensing devices is driving the proliferation of data, as these devices are able to generate, collect, and transmit vast amounts of data in real time.

        The data generated by IoT and sensing devices can be used for a variety of purposes, including real-time decision making, trend analysis, and predictive modeling. The ability to collect and analyze this data in real time allows organizations to make more informed decisions and respond more quickly to changing circumstances. As the number of IoT and sensing devices continues to grow, the amount of data being generated and analyzed will also increase, leading to even greater insights and opportunities for organizations.

    ??? tip "The Impact of Mobile and Cloud Computing on Data Generation"
        ### The Impact of Mobile and Cloud Computing on Data Generation

        <figure markdown>
            ![Cloud Formations](/assets/data-is-beautiful/cloud-formations.png)
        </figure>
    
        Mobile and cloud computing are driving the rapid growth of data generation. The proliferation of mobile devices and the increasing use of cloud-based services have made it easier for people to access and use these technologies, leading to a significant increase in the amount of data being produced.

        Analytics users expect an exceptional experience when interacting with data, and we want them to spend more time engaging with insights. This means that we need to focus on delivering a user-friendly interface and ensuring that data is easily accessible.

        The pandemic has also contributed to the increase in data generation, as more people turned to online platforms for services such as grocery delivery. This trend is likely to continue as the use of mobile and cloud technologies becomes more widespread.

        As the amount of data being generated continues to grow, organizations need to carefully consider how much data to collect and analyze, and how long to retain it. By identifying the systems, users, and assets that are generating the most relevant data, we can more effectively scope problems and take action to address them. Baselines and trending are also important for understanding how IT services are performing and responding to user needs.

    ??? tip "The Importance of Data in a Pandemic"
        ### The Importance of Data in a Pandemic
        
        The pandemic brought attention to the crucial role that data plays in decision making. From tracking case numbers and infection rates to determining the capacity of hospitals, data became a driving force in understanding and responding to the crisis. This emphasized the need for real-time insights and quick response times in order to keep critical services running and secure. The pandemic also highlighted the importance of defining what is essential, both in terms of services and data. Ensuring the availability of these essential services and data requires a strong and efficient IT infrastructure, which can be achieved through the use of analytics and machine-speed response.

??? note "Data-Driven Digital Organizations"
    ## Data-Driven Digital Organizations

    As technology has become increasingly important for businesses, governments, and schools, the need for secure, efficient, and effective technology solutions has grown. While technology vendors have made significant progress in providing customers with increased security, visibility, and risk reduction, many organizations still struggle to integrate and make sense of their technology and data. There are various approaches to securing and optimizing operations, but choosing the best one can be a challenge. It is important for organizations to consider factors such as speed, budget, and overall fit with their needs and goals as they evaluate their options. It's also important to remember that the journey to becoming a digital organization is not always a quick one, and may involve transitioning from traditional approaches like statistical sampling to more modern approaches like individual data point analysis.

    <figure markdown>
        ![Differences in visibility](/assets/data-is-beautiful/visibility.png){ width="800" }
        <figcaption>Caption: Differences in visibility.</figcaption>
    </figure>

    Using real-time insights, organizations can take tailor-made actions to address specific issues and optimize their operations. By being able to ask questions, identify trends and patterns, and detect deviations from established baselines, organizations can improve their decision-making and take more targeted, effective actions. This can be especially important for leadership, stakeholders, and users such as analysts, engineers, and policy makers who rely on data and analytics to inform their work. To support these efforts, IT teams may need to reinvent themselves and provide self-service analytics tools and resources to empower users to access and analyze data on their own. Additionally, some organizations now exist entirely in the digital world and may not have physical offices, making it even more critical that they have robust analytics capabilities to support their operations.

    <figure markdown>
        ![Data driven culture](/assets/data-is-beautiful/data-driven-culture.png)
    </figure>

    ??? question "How do you detect emerging schemas, patterns, or trends?"
        <strong>Answer:</strong> Descriptive analytics

??? note "Introducing Splunk’s Operationalizing Data Analytics Methodology"
    ## Introducing Splunk’s Operationalizing Data Analytics Methodology

    <figure markdown>
        ![ODAM Overview](/assets/data-is-beautiful/odam-overview.png)
    </figure>

    Splunk’s ODAM (Operationalizing Data Analytics Methodology) is a methodology that helps organizations bring data analytics to the next level. Not only can it provide an efficient way to define, plan, execute, and measure data analytics initiatives, but it also can play a critical role in an organization's cybersecurity. By following this methodology, organizations can use data analytics to improve their threat detection capabilities, streamline incident investigation and make faster and more informed decisions in their incident response efforts. This can lead to more efficient and effective cybersecurity operations, help organizations stay ahead of emerging threats, and ultimately minimize the impact of security incidents on the organization and its stakeholders.

    Through ODAM, you will be able to mature and operationalize its data analytics capabilities, enabling it to drive business value and support decision-making across multiple departments and use cases. By leveraging data analytics, your organization can accelerate progress and lead the way in using data to drive business success. 

    The key components of ODAM are outlined below.

    <figure markdown>
        ![ODAM Components](/assets/data-is-beautiful/odam-components.png){ width="800" }
    </figure>

??? note "The Problems ODAM Is Attempting to Solve"
    ## The Problems ODAM Is Attempting to Solve

    ??? tip "What problem is ODAM trying to solve?"
        ### What problem is ODAM trying to solve?

        ODAM (Operationalizing Data Analytics Methodology) is a comprehensive methodology that helps organizations build a data-driven culture and achieve measurable business outcomes by providing a framework for defining, planning, executing, and measuring data analytics initiatives. It aims to solve the problem of organizations not being able to fully leverage the potential of data analytics and make data-driven decisions. Without a clear methodology and framework, organizations may struggle to align their data analytics efforts with their strategic goals and objectives, and may not be able to maximize the value of their data assets. ODAM provides a structured approach to operationalizing data analytics, enabling organizations to mature and operationalize their data analytics capabilities, and drive business value and support decision-making across multiple departments and use cases.

    ??? tip "Why would an organization use ODAM?"
        ### Why would an organization use ODAM?

        An organization would use ODAM to mature and operationalize their data analytics capabilities to drive business value and support decision-making across multiple departments and use cases. ODAM provides a framework for defining, planning, executing, and measuring data analytics initiatives, which can help organizations align their data analytics efforts with their strategic goals and objectives, and maximize the value of their data assets. Additionally, ODAM helps organizations establish a data-driven culture and provides best practices and resources for implementing data analytics in an effective and efficient manner.
    
    ??? tip "How can ODAM save your organization money?"
        ### How can ODAM save your organization money?

        One of the main ways is by increasing efficiency and reducing manual workflows in security operations. By automating certain processes, such as incident investigation and response, organizations can reduce the amount of time and resources required to manage security incidents. Additionally, by implementing advanced security analytics and a risk-based alerting framework, ODAM can help organizations identify and prioritize high-risk incidents more effectively, allowing them to focus their resources on the most critical threats.

        Another way ODAM can save organizations money is by reducing the risk of data breaches and other security incidents. By providing a framework for defining, planning, executing, and measuring data analytics initiatives, ODAM can help organizations mature and operationalize their data analytics capabilities, which can improve their overall security posture and reduce their risk of a data breach.

        ODAM can also help organizations save money by reducing the costs associated with compliance. By providing a framework for monitoring and reporting on compliance-related activities, ODAM can help organizations demonstrate compliance with regulatory requirements, which can help them avoid costly fines and penalties.

    ??? tip "Where does one start?!"
        ### Where does one start?!

        Organizations often face complex problems and challenges that they believe could be addressed through data analytics. However, they may not know where to start. To overcome these problems, ODAM can empower organizations to take the following steps.

        <figure markdown>
            ![Overcome Problems](/assets/data-is-beautiful/overcome-problems.png)
        </figure>

    ---
    <p class="center-text larger-text">A problem is <span class="color-bold">noticed</span>,</p>
    <p class="center-text larger-text">the problem is <span class="color-bold">understood</span>,</p>
    <p class="center-text larger-text"><span class="color-bold">action</span> is taken, and</p>
    <p class="center-text larger-text">the problem is <span class="color-bold">resolved</span>.</p>